{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import pymixconsole as pymc\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pymixconsole \n",
    "\n",
    "pymixconsole is a lightweight Python library for implementing and controlling a headless multitrack mixing console. It aims to provide a simple interface to be controlled programatically allowing for more control compared to scripting in pre-existing DAWs, and is easily extensible to allow for advanced behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example audio\n",
    "\n",
    "Before we get started let's first load a simple mono recording of an electric guitar that we will use for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load an example audio file to use in our demonstrations\n",
    "x, fs = sf.read('../signals/e_gtr_short.wav')\n",
    "print(f\"Loaded {x.shape[0]} samples at fs={fs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor\n",
    "\n",
    "The lowest level object that makes up a mixing console is the `Processor`. A `Processor` object generally has a set of `Parameter` objects that define how the device can be configured and also contains a `process()` method that takes in a block of mono or stereo audio and produces and output. One of the simplest processors is the `Gain` processor, which can be used as shown below. First we create an instance of the processor and then we adjust its gain value to be -12.0 dB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = pymc.processors.Gain(block_size=512, sample_rate=44100)\n",
    "gain.parameters.gain.value = -12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to use this processor to process our audio. To do this we will iterate over our audio file, each time passing a new chunk of 512 samples to the gain processor, storing the output into a new array with the same size as the input audio stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.empty(shape=(x.shape[0],))\n",
    "\n",
    "for n in range(x.shape[0]//512):\n",
    "    start = n * 512\n",
    "    stop = start + 512\n",
    "    y[start:stop] = gain.process(x[start:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(data=x, rate=fs, normalize=False))\n",
    "ipd.display(ipd.Audio(data=y, rate=fs, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gain isn't too interesting so let's try something a bit cooler like Reverb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb = pymc.processors.Reverb(block_size=512, sample_rate=44100)\n",
    "reverb.parameters.dry_mix.value = 0.3\n",
    "reverb.parameters.wet_mix.value = 0.03\n",
    "reverb.parameters.room_size.value = 0.7\n",
    "\n",
    "# the output of the reverb is always stereo\n",
    "y = np.empty(shape=(x.shape[0],2))\n",
    "\n",
    "for n in range(x.shape[0]//512):\n",
    "    start = n * 512\n",
    "    stop = start + 512\n",
    "    y[start:stop] = reverb.process(x[start:stop])\n",
    "      \n",
    "ipd.display(ipd.Audio(data=x, rate=fs, normalize=True))\n",
    "ipd.display(ipd.Audio(data=y.T, rate=fs, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter\n",
    "\n",
    "I may have lied slightly, the `Parameter` class is slightly lower than the `Processor` class and every processor contains a list of `Parameters`. These parameters help to define the operation of the processor and provide an interface for the user to change its behaviour. \n",
    "\n",
    "To see all the parameters for a processor just call the print function on a processor's `ParameterList` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reverb.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that every parameter has a name (string) as well as a current `value`. It also has a kind designation which is basically the parameter's type. It also has a default value so that it can be reset and a range that defines a min and max values. In the case of the string kind there is a list of possible options instead. We saw in the above examples how to modify the `value` of any parameter, but the most useful behaviour here is the `randmoize()` method.\n",
    "\n",
    "We can actually call the `randomize()` method for the reverb processor and it will go through and indivually call the `randomize()` method for each of its parameters. We see below that the values have been randomized. What we don't see is that something special is going on behind the scenes with regards to how each parameter gets randomized. To keep it short, when a `Parameter` is defined the creator can specify whether they want to sample new values from a uniform distribution or from a Gaussian (with defined mean and stddev). We won't get into this more now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb.randomize()\n",
    "print(reverb.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also see what happens if we try to change a parameter value to something beyond its valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverb.parameters.width.value = 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel\n",
    "\n",
    "The next level is the `Channel`. A Channel contains a number of processors, and when a block of data is passed to a channel it will apply all of its processors to that data in series. There are actually three kinds of processors in a channel: pre-processors, core-processors, and post-procesors. The reason for the distinctions in that during the `randomize()` process for a channel this ensure that only the core-processors can have their order shuffled. The pre and post-processors will always retain the order they are initiatlized to. This is needed for example for things like the `Panner`, which we want to ALWAYS be the last element in the signal chain for the channel. \n",
    "\n",
    "In the following example we will instantiate a new channel and then use it process our audio signal. \n",
    "\n",
    "By default the structure of a channel will be the following:\n",
    "\n",
    "**pre-processors**:  pre-gain -> polarity-inverter\n",
    "\n",
    "**core-processors**: equaliser -> compressor\n",
    "\n",
    "**post-processors**: post-gain -> panner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = pymc.channel.Channel(block_size=512, sample_rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply our processing on the guitar signal from before in the exact same way, except this time we will call the `process()` method of the channel. Before we apply the processing with the default settings, let's change the equaliser and compressor (by default they will do no processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets grab a reference for the equaliser and compressor using their default names\n",
    "eq   = channel.processors.get(\"eq\")\n",
    "comp = channel.processors.get(\"compressor\")\n",
    "\n",
    "# now we can adjust the equaliser to filter out the low end\n",
    "eq.parameters.low_shelf_freq.value = 420.0 # Hz\n",
    "eq.parameters.low_shelf_gain.value = -24.0 # dB\n",
    "\n",
    "# and dial in the compressor threshold and ratio\n",
    "comp.parameters.threshold.value = -32.0 # dB\n",
    "comp.parameters.ratio.value     =  10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output of the channel is always stereo\n",
    "y = np.empty(shape=(x.shape[0],2))\n",
    "\n",
    "for n in range(x.shape[0]//512):\n",
    "    start = n * 512\n",
    "    stop = start + 512\n",
    "    y[start:stop] = channel.process(x[start:stop])\n",
    "      \n",
    "ipd.display(ipd.Audio(data=x, rate=fs, normalize=True))\n",
    "ipd.display(ipd.Audio(data=y.T, rate=fs, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to add another processor the a channel it's very easy. \n",
    "\n",
    "For example, let's try adding our reverb processor from earlier to this channel, right after the compressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel.processors.add(reverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output of the channel is always stereo\n",
    "y = np.empty(shape=(x.shape[0],2))\n",
    "\n",
    "for n in range(x.shape[0]//512):\n",
    "    start = n * 512\n",
    "    stop = start + 512\n",
    "    y[start:stop] = channel.process(x[start:stop])\n",
    "      \n",
    "ipd.display(ipd.Audio(data=x, rate=fs, normalize=True))\n",
    "ipd.display(ipd.Audio(data=y.T, rate=fs, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Console\n",
    "\n",
    "Finally, we have made it to the top most level. Here we take all of the components from before and combine them to build an entire mixing console, complete, with channels, busses, processors, and all. \n",
    "\n",
    "When we create a console we will need to supply a `block_size` and `sample_rate` just like with all of the previous objects. But, in addition we will need to ask for a certain number of channels. This will create a new channel for each one with the default settings. This will also create two busses (one for reverb, and one for delay), as well as a special bus, the master, which has a equaliser and compressor. Before we get too far into the details let's create a console and try to process some audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this part a bit trickier since we need to create an array of mono input signals with the shape `[samples, tracks]`. Eventually this will be wrapped up into the `Multitrack` class which is still a work in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfiles = glob.glob(\"../signals/multitrack/*.wav\")\n",
    "\n",
    "block_size = 16384\n",
    "\n",
    "# counters\n",
    "ch_idx     = 0\n",
    "n_samples  = 0\n",
    "n_channels = 0\n",
    "\n",
    "# first loop over all the files checking their info to create array\n",
    "for mfile in mfiles:\n",
    "\n",
    "    info = sf.info(mfile)\n",
    "    tmp_samples = int(info.duration * info.samplerate)\n",
    "    \n",
    "    if tmp_samples > n_samples:\n",
    "        n_samples = tmp_samples\n",
    "    \n",
    "    for i in range(info.channels):\n",
    "        n_channels += 1\n",
    "        \n",
    "z = np.zeros(shape=(n_samples, n_channels))\n",
    "\n",
    "for mfile in mfiles:\n",
    "    \n",
    "    info  = sf.info(mfile)\n",
    "    d, fs = sf.read(mfile)\n",
    "    \n",
    "    tmp_samples = int(info.duration * info.samplerate)\n",
    "    if tmp_samples < n_samples:\n",
    "        pdsize = n_samples - tmp_samples - 1\n",
    "        d = np.pad(d, (0, pdsize))\n",
    "    \n",
    "    if info.channels > 1:\n",
    "        z[:,ch_idx] = d[:,0]\n",
    "        ch_idx += 1\n",
    "        z[:,ch_idx] = d[:,1] \n",
    "        ch_idx += 1\n",
    "    else:        \n",
    "        z[:,ch_idx] = d\n",
    "        ch_idx += 1\n",
    "\n",
    "print(z.shape, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our array of multitrack data let's create a console to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console = pymc.Console(block_size=block_size, sample_rate=fs, num_channels=n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will follow the same process as before iterating over each block of the input. In the future the `Multitrack` object will make this a big simpler. Note that this can take a bit of time since we are essentially performing the same process as \"bouncing\" or rendering the full track in the DAW. This still should be quite a bit faster than realtime, and we will get an improvement if we use a larger `block_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(shape=(n_samples, 2))\n",
    "\n",
    "for n in range(n_samples//block_size):\n",
    "\n",
    "    start = n * block_size\n",
    "    stop  = start + block_size\n",
    "\n",
    "    sys.stdout.write(f\"* {n:3d}/{n_samples//block_size:3d}\\r\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    y[start:stop,:] = console.process_block(z[start:stop,:])\n",
    "\n",
    "ipd.display(ipd.Audio(data=y.T, rate=fs, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "def show_svg(svg):\n",
    "    return ipd.HTML(f\"\"\"<img src=\"{svg}\"></img>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mix is pretty boring since all settings are at the default setting and the FX busses are turned off. So to make a more intersting mix we are going to want to change some parameters around. Since the console is large (16 channels of mono audio), it would be nice to visual the console. We can do this with the `render_diagram()` method. This will give us a full look at the console set up and the parameter settings for every processor in the console. This is quite large so you might want to open in another window and take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.randomize()\n",
    "console.render_diagram()\n",
    "show_svg('./pymixconsole_diagram.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could do into each channel and each processor to set some values to make our mix more interesting, but let's take the easy way out and just call the console levle `randomize()` method which will randomize the entirety of the console (but in a relvatively smart way). Then we can process the audio tracks again and listen to the new output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.randomize()\n",
    "\n",
    "for n in range(n_samples//block_size):\n",
    "\n",
    "    start = n * block_size\n",
    "    stop  = start + block_size\n",
    "\n",
    "    sys.stdout.write(f\"* {n:3d}/{n_samples//block_size:3d}\\r\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    y[start:stop,:] = console.process_block(z[start:stop,:])\n",
    "\n",
    "ipd.display(ipd.Audio(data=y.T, rate=fs, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a good mix by any means but we can hear some different elements, effects, and panning now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize\n",
    "\n",
    "The final import method to talk about is the `serialize()` method. This is a special method that can be called at any level that packages up all the details about how the console is configured. This serves a special purpose, since we want to build a deep learning model that learns how to perform that linear and nonlinear transformations of a mixing console. This method then produces a vector of all the parameter settings with some nice features. Let's first look at the result of doing this at the lower level of the `Processor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eq.parameters.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this gives a dictionary are all the current values of each parameter in this processor. This is nice but not exactly what we want. We can also send in keyword arguments to change how this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eq.parameters.serialize(normalize=True, one_hot_encode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this has normalized all the values between 0-1 from min to max. Additionally it should one-hot-encode any string parameters that can take on a few different values. To get a better example of what this looks like let's try it for the entire console now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel.serialize(normalize=True, one_hot_encode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get this ready for something like a model trained in PyTorch we can use a function like this to convert it into a single array with values that range from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_params(serialized_params):\n",
    "\n",
    "    vector = []\n",
    "\n",
    "    for processor_type, processors in serialized_params.items():\n",
    "        for processor in processors:\n",
    "            for name, parameters in processor.items():\n",
    "                for name, parameter in parameters.items():\n",
    "                    if isinstance(parameter, np.ndarray):\n",
    "                        for val in parameter:\n",
    "                            vector.append(val)\n",
    "                    else:\n",
    "                        vector.append(parameter)\n",
    "\n",
    "    return np.array(vector).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorize_params(channel.serialize(normalize=True, one_hot_encode=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_processor(x, processor, stereo=False, normalize=True):\n",
    "\n",
    "    if stereo:\n",
    "        y = np.empty(shape=(x.shape[0],2))\n",
    "    else:\n",
    "        y = np.empty(shape=(x.shape[0],))\n",
    "\n",
    "    for n in range(x.shape[0]//processor.block_size):\n",
    "        start = n * processor.block_size\n",
    "        stop = start + processor.block_size\n",
    "        y[start:stop] = processor.process(x[start:stop])\n",
    "\n",
    "    ipd.display(ipd.Audio(data=x, rate=fs, normalize=normalize))\n",
    "    ipd.display(ipd.Audio(data=y.T, rate=fs, normalize=normalize))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processors Overiew\n",
    "\n",
    "In this section we will briefly cover each processor and run it over our electric guitar sample from before.\n",
    "\n",
    "### Gain\n",
    "\n",
    "As we saw before this is the most simple control over the level of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = pymc.processors.Gain(block_size=512, sample_rate=fs)\n",
    "gain.parameters.gain.value = 12.0\n",
    "\n",
    "print(gain.parameters)\n",
    "\n",
    "apply_processor(x.copy(), gain, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity Inverter\n",
    "\n",
    "The polarity inverter is a simple processor that flips the polarity of the input signal. While this may not seem very useful it is fairly important when you have multiple microphones, as it can be used to correct phase issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverter = pymc.processors.PolarityInverter(block_size=512, sample_rate=fs)\n",
    "inverter.parameters.invert.value = True\n",
    "\n",
    "print(inverter.parameters)\n",
    "\n",
    "apply_processor(x.copy(), inverter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "panner = pymc.processors.Panner(block_size=512, sample_rate=fs)\n",
    "# pan it all the way to the left\n",
    "panner.parameters.pan.value = 0.0 \n",
    "\n",
    "print(panner.parameters)\n",
    "\n",
    "apply_processor(x.copy(), panner, stereo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equaliser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = pymc.processors.Equaliser(block_size=512, sample_rate=fs)\n",
    "eq.parameters.low_shelf_freq.value  = 120\n",
    "eq.parameters.low_shelf_gain.value  = 12.0\n",
    "eq.parameters.first_band_freq.value = 800.0\n",
    "eq.parameters.first_band_gain.value = -20.0\n",
    "eq.parameters.first_band_q.value    =  0.3\n",
    "eq.parameters.high_shelf_freq.value = 8000\n",
    "eq.parameters.high_shelf_gain.value = 12.0\n",
    "\n",
    "print(eq.parameters)\n",
    "\n",
    "apply_processor(x.copy(), eq, stereo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = pymc.processors.Compressor(block_size=512, sample_rate=fs)\n",
    "\n",
    "print(compressor.parameters)\n",
    "\n",
    "apply_processor(x.copy(), compressor, stereo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion = pymc.processors.Distortion(block_size=512, sample_rate=fs)\n",
    "distortion.parameters.factor.value = 9.0\n",
    "\n",
    "print(distortion.parameters)\n",
    "\n",
    "apply_processor(2.0 * x.copy(), distortion, stereo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delay = pymc.processors.Delay(block_size=512, sample_rate=fs)\n",
    "delay.parameters.wet_mix.value = 0.3\n",
    "delay.parameters.delay.value = 20000\n",
    "delay.parameters.feedback.value = 0.6\n",
    "\n",
    "print(delay.parameters)\n",
    "\n",
    "apply_processor(x.copy(), delay, stereo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb = pymc.processors.Reverb(block_size=512, sample_rate=fs)\n",
    "reverb.parameters.damping.value = 1.0\n",
    "reverb.parameters.dry_mix.value = 0.8\n",
    "reverb.parameters.wet_mix.value = 0.15\n",
    "reverb.parameters.room_size.value = 0.6\n",
    "reverb.parameters.width.value = 1.0\n",
    "\n",
    "print(reverb.parameters)\n",
    "\n",
    "apply_processor(x.copy(), reverb, stereo=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
